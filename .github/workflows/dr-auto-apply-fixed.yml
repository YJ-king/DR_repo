name: DR Terraform Apply

on:
  workflow_dispatch:  # ✅ 수동 실행용 (나중에 Cloud Run에서 API로 호출 가능)

jobs:
  terraform-apply:
    name: Terraform Apply on AWS
    runs-on: ubuntu-latest

    permissions:
      id-token: write   # ✅ GitHub OIDC를 위해 필요
      contents: read

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: arn:aws:iam::723165663216:role/github-actions-terraform-role
          aws-region: ap-northeast-2

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.7.5

      - name: Terraform Init
        run: terraform -chdir=infra/dr_terraform/envs init

      - name: Terraform Apply
        run: terraform -chdir=infra/dr_terraform/envs apply -auto-approve

      - name: Install dependencies (kubectl, awscli, helm)
        run: |
          sudo apt-get update -y
          sudo apt-get install -y curl unzip git apt-transport-https ca-certificates gnupg lsb-release jq

          # kubectl
          KUBECTL_VERSION=$(curl -sL https://dl.k8s.io/release/stable.txt)
          curl -LO "https://dl.k8s.io/release/${KUBECTL_VERSION}/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

          # Helm
          curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

      - name: Connect to EKS
        run: |
          aws eks update-kubeconfig --region ap-northeast-2 --name drb-eks-cluster

      - name: Get EKS Node Role ARN
        shell: bash
        run: |
          echo "🔧 Extracting clean NODE_ROLE_ARN"
          terraform -chdir=infra/dr_terraform/envs init -input=false

          TF_RAW=$(terraform -chdir=infra/dr_terraform/envs output eks_node_role_arn 2>/dev/null || echo "")
          echo "🧪 Raw Output: [$TF_RAW]"

          TF_CLEAN=$(echo "$TF_RAW" | tr -d '"' | grep -Eo '^arn:aws:iam::[0-9]+:role/[A-Za-z0-9+=,.@_-]+$' | head -n 1)

          echo "📌 Cleaned: [$TF_CLEAN]"

          if [[ -z "$TF_CLEAN" ]]; then
            echo "❌ NODE_ROLE_ARN not found"
            exit 1
          fi

          echo "NODE_ROLE_ARN=$TF_CLEAN" >> "$GITHUB_ENV"


      - name: Generate aws-auth.yaml
        run: bash scripts/gen-aws-auth.sh
        env:
          NODE_ROLE_ARN: ${{ env.NODE_ROLE_ARN }}


      - name: Apply aws-auth.yaml
        run: |
          kubectl apply -f infra/dr_terraform/envs/aws-auth.yaml

      - name: Install ALB Controller CRDs
        run: |
          kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/main/helm/aws-load-balancer-controller/crds/crds.yaml

      - name: Extract ALB IRSA Role ARN
        id: get_role
        run: |
          echo "🔍 Extracting ALB IRSA Role ARN"

          TF_RAW=$(terraform -chdir=infra/dr_terraform/envs output alb_irsa_role_arn 2>/dev/null || echo "")
          echo "🧪 Raw: [$TF_RAW]"

          ROLE_ARN=$(echo "$TF_RAW" | tr -d '"' | grep -Eo '^arn:aws:iam::[0-9]+:role/[A-Za-z0-9+=,.@_-]+$' | head -n 1)
          echo "📌 Cleaned: [$ROLE_ARN]"

          if [[ -z "$ROLE_ARN" ]]; then
            echo "❌ ROLE_ARN not found"
            exit 1
          fi

          echo "role_arn=$ROLE_ARN" >> "$GITHUB_OUTPUT"

      - name: Install ALB Controller with Helm
        shell: bash
        env:
          ROLE_ARN: ${{ steps.get_role.outputs.role_arn }}
        run: |
          echo "📌 Installing ALB Controller with Helm"
    
          if [[ -z "$ROLE_ARN" ]]; then
            echo "❌ ROLE_ARN is missing! Aborting Helm install."
            exit 1
          fi

          VPC_ID=$(aws eks describe-cluster \
            --name drb-eks-cluster \
            --region ap-northeast-2 \
            --query "cluster.resourcesVpcConfig.vpcId" \
            --output text)

          helm repo add eks https://aws.github.io/eks-charts
          helm repo update

          helm upgrade -i aws-load-balancer-controller eks/aws-load-balancer-controller \
            -n kube-system \
            --set clusterName=drb-eks-cluster \
            --set serviceAccount.create=true \
            --set serviceAccount.name=aws-load-balancer-controller \
            --set serviceAccount.annotations."eks\.amazonaws\.com/role-arn"="$ROLE_ARN" \
            --set region=ap-northeast-2 \
            --set vpcId="$VPC_ID" \
            --set image.repository=602401143452.dkr.ecr.ap-northeast-2.amazonaws.com/amazon/aws-load-balancer-controller


      - name: Wait for ALB Controller Ready
        run: kubectl rollout status deployment/aws-load-balancer-controller -n kube-system

      - name: Create imagePullSecret for GCP Artifact Registry
        run: |
          echo '${{ secrets.GCP_AR_KEY_JSON }}' > key.json

          kubectl delete secret regcred -n default --ignore-not-found

          kubectl create secret docker-registry regcred \
          --docker-server=asia-northeast3-docker.pkg.dev \
          --docker-username=_json_key \
          --docker-password="$(cat key.json)" \
          --docker-email=ci@github.com \
          -n default

      - name: Generate application.properties using RDS Endpoint
        run: |
          DB_HOST=$(terraform -chdir=infra/dr_terraform/envs output -raw rds_endpoint | grep -Eo '^[a-z0-9.-]+\.rds\.amazonaws\.com:3306')
          DB_NAME="petclinic"
          DB_USER="petuser"
          DB_PASSWORD=$(kubectl get secret db-secret -o jsonpath="{.data.password}" | base64 -d)

          export DB_HOST DB_NAME DB_USER DB_PASSWORD
          envsubst < was/application.properties.tpl > was/application.properties

      - name: Create or update ConfigMap for WAS
        run: |
          kubectl create configmap was-config \
          --from-file=application.properties=was/application.properties \
          -o yaml --dry-run=client | kubectl apply -f -

      - name: Restart WAS Deployment
        run: |
          kubectl rollout restart deployment was-deployment

      - name: Deploy Web & WAS YAMLs
        run: |
          kubectl apply -f web/
          kubectl apply -f was/


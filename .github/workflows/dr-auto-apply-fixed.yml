name: DR Terraform Apply

on:
  workflow_dispatch:  # ‚úÖ ÏàòÎèô Ïã§ÌñâÏö© (ÎÇòÏ§ëÏóê Cloud RunÏóêÏÑú APIÎ°ú Ìò∏Ï∂ú Í∞ÄÎä•)

jobs:
  terraform-apply:
    name: Terraform Apply on AWS
    runs-on: ubuntu-latest

    permissions:
      id-token: write   # ‚úÖ GitHub OIDCÎ•º ÏúÑÌï¥ ÌïÑÏöî
      contents: read

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: arn:aws:iam::723165663216:role/github-actions-terraform-role
          aws-region: ap-northeast-2

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.7.5

      - name: Set start time
        run: echo "START_TIME=$(date -u +%Y-%m-%dT%H:%M:%SZ)" >> $GITHUB_ENV

      - name: Terraform Init
        run: terraform -chdir=infra/dr_terraform/envs init

      - name: Terraform Apply
        run: terraform -chdir=infra/dr_terraform/envs apply -auto-approve

      - name: Set Terraform end time
        run: echo "TERRAFORM_END_TIME=$(date -u +%Y-%m-%dT%H:%M:%SZ)" >> $GITHUB_ENV

      - name: Install dependencies (kubectl, awscli, helm)
        run: |
          sudo apt-get update -y
          sudo apt-get install -y curl unzip git apt-transport-https ca-certificates gnupg lsb-release jq

          # kubectl
          KUBECTL_VERSION=$(curl -sL https://dl.k8s.io/release/stable.txt)
          curl -LO "https://dl.k8s.io/release/${KUBECTL_VERSION}/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

          # Helm
          curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

      - name: Authenticate Docker to Artifact Registry
        run: |
          echo '${{ secrets.GCP_AR_KEY_JSON }}' > key.json
          gcloud auth activate-service-account --key-file=key.json
          gcloud auth configure-docker asia-northeast3-docker.pkg.dev --quiet

      - name: Connect to EKS
        run: |
          aws eks update-kubeconfig --region ap-northeast-2 --name drb-eks-cluster

      - name: Get EKS Node Role ARN
        shell: bash
        run: |
          echo "üîß Extracting clean NODE_ROLE_ARN"
          terraform -chdir=infra/dr_terraform/envs init -input=false

          TF_RAW=$(terraform -chdir=infra/dr_terraform/envs output eks_node_role_arn 2>/dev/null || echo "")
          echo "üß™ Raw Output: [$TF_RAW]"

          TF_CLEAN=$(echo "$TF_RAW" | tr -d '"' | grep -Eo '^arn:aws:iam::[0-9]+:role/[A-Za-z0-9+=,.@_-]+$' | head -n 1)

          echo "üìå Cleaned: [$TF_CLEAN]"

          if [[ -z "$TF_CLEAN" ]]; then
            echo "‚ùå NODE_ROLE_ARN not found"
            exit 1
          fi

          echo "NODE_ROLE_ARN=$TF_CLEAN" >> "$GITHUB_ENV"


      - name: Generate aws-auth.yaml
        run: bash scripts/gen-aws-auth.sh
        env:
          NODE_ROLE_ARN: ${{ env.NODE_ROLE_ARN }}


      - name: Apply aws-auth.yaml
        run: |
          kubectl apply -f infra/dr_terraform/envs/aws-auth.yaml

      - name: Install ALB Controller CRDs
        run: |
          kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/main/helm/aws-load-balancer-controller/crds/crds.yaml

      - name: Extract ALB IRSA Role ARN
        id: get_role
        run: |
          echo "üîç Extracting ALB IRSA Role ARN"

          TF_RAW=$(terraform -chdir=infra/dr_terraform/envs output alb_irsa_role_arn 2>/dev/null || echo "")
          echo "üß™ Raw: [$TF_RAW]"

          ROLE_ARN=$(echo "$TF_RAW" | tr -d '"' | grep -Eo '^arn:aws:iam::[0-9]+:role/[A-Za-z0-9+=,.@_-]+$' | head -n 1)
          echo "üìå Cleaned: [$ROLE_ARN]"

          if [[ -z "$ROLE_ARN" ]]; then
            echo "‚ùå ROLE_ARN not found"
            exit 1
          fi

          echo "role_arn=$ROLE_ARN" >> "$GITHUB_OUTPUT"

      - name: Install ALB Controller with Helm
        shell: bash
        env:
          ROLE_ARN: ${{ steps.get_role.outputs.role_arn }}
        run: |
          echo "üìå Installing ALB Controller with Helm"
    
          if [[ -z "$ROLE_ARN" ]]; then
            echo "‚ùå ROLE_ARN is missing! Aborting Helm install."
            exit 1
          fi

          VPC_ID=$(aws eks describe-cluster \
            --name drb-eks-cluster \
            --region ap-northeast-2 \
            --query "cluster.resourcesVpcConfig.vpcId" \
            --output text)

          helm repo add eks https://aws.github.io/eks-charts
          helm repo update

          helm upgrade -i aws-load-balancer-controller eks/aws-load-balancer-controller \
            -n kube-system \
            --set clusterName=drb-eks-cluster \
            --set serviceAccount.create=true \
            --set serviceAccount.name=aws-load-balancer-controller \
            --set serviceAccount.annotations."eks\.amazonaws\.com/role-arn"="$ROLE_ARN" \
            --set region=ap-northeast-2 \
            --set vpcId="$VPC_ID" \
            --set image.repository=602401143452.dkr.ecr.ap-northeast-2.amazonaws.com/amazon/aws-load-balancer-controller


      - name: Wait for ALB Controller Ready
        run: kubectl rollout status deployment/aws-load-balancer-controller -n kube-system

      - name: Create imagePullSecret for GCP Artifact Registry
        run: |
          echo '${{ secrets.GCP_AR_KEY_JSON }}' > key.json

          kubectl delete secret regcred -n default --ignore-not-found

          kubectl create secret docker-registry regcred \
          --docker-server=asia-northeast3-docker.pkg.dev \
          --docker-username=_json_key \
          --docker-password="$(cat key.json)" \
          --docker-email=ci@github.com \
          -n default

      - name: Get RDS endpoint and inject into properties/pom.xml
        shell: bash
        run: |
          echo "üîß Extracting clean RDS endpoint from terraform output"
    
          TF_RAW=$(terraform -chdir=infra/dr_terraform/envs output -raw rds_endpoint 2>/dev/null || echo "")
    
          RDS_ENDPOINT=$(echo "$TF_RAW" | grep -Eo '^[a-z0-9.-]+\.rds\.amazonaws\.com:3306' | head -n 1)

          if [[ -z "$RDS_ENDPOINT" ]]; then
            echo "‚ùå Failed to extract RDS endpoint from: [$TF_RAW]"
            exit 1
          fi

          sed -i "s|<DB_HOST>|$RDS_ENDPOINT|g" was/petclinic_btc/src/main/resources/spring/data-access.properties
          sed -i "s|<DB_HOST>|$RDS_ENDPOINT|g" was/petclinic_btc/src/main/resources/application.properties
          sed -i "s|<DB_HOST>|$RDS_ENDPOINT|g" was/petclinic_btc/pom.xml

      - name: Maven Build for WAR
        run: |
          cd was/petclinic_btc
          ./mvnw clean package -DskipTests -PMySQL

      - name: Debug WAR contents
        run: |
          unzip -p was/petclinic_btc/target/petclinic.war WEB-INF/classes/application.properties | grep DB_HOST || echo "‚úÖ No DB_HOST found"
      - name: Build Docker image for WAS
        run: |
          docker build --no-cache -t asia-northeast3-docker.pkg.dev/kdt1-finalproject/yj-repo/yj-was:was-dr-03 ./was

      - name: Push Docker image to Artifact Registry
        run: |
          docker push asia-northeast3-docker.pkg.dev/kdt1-finalproject/yj-repo/yj-was:was-dr-03

      - name: Get RDS Endpoint from Terraform Output
        id: rds
        shell: bash
        run: |
          TF_RAW=$(terraform -chdir=infra/dr_terraform/envs output -raw rds_endpoint 2>/dev/null || echo "")
          RDS_ENDPOINT=$(echo "$TF_RAW" | grep -Eo '^[a-z0-9.-]+\.rds\.amazonaws\.com:3306' | head -n 1)
          if [[ -z "$RDS_ENDPOINT" ]]; then
            echo "‚ùå Failed to extract RDS endpoint from: [$TF_RAW]"
            exit 1
          fi

          RDS_HOST="${RDS_ENDPOINT%%:*}"
          echo "‚úÖ RDS_ENDPOINT: $RDS_ENDPOINT"
          echo "‚úÖ RDS_HOST: $RDS_HOST"
          echo "rds_host=$RDS_HOST" | tee -a "$GITHUB_OUTPUT"

      - name: Create db-secret from GitHub Secrets
        env:
          DB_USER: petuser
          DB_NAME: petclinic
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          RDS_HOST: ${{ steps.rds.outputs.rds_host }}
        run: |
          echo "üîê Creating db-secret..."
          cat <<EOF | kubectl apply -f -
          apiVersion: v1
          kind: Secret
          metadata:
            name: yj-db-secret
            namespace: default
          type: Opaque
          stringData:
            host: $RDS_HOST
            username: $DB_USER
            password: $DB_PASSWORD
            dbname: $DB_NAME
          EOF

      - name: Get IRSA Role ARN from Terraform Output
        id: irsa
        run: |
          S3_ROLE_ARN=$(terraform -chdir=infra/dr_terraform/envs output -raw role_arn | tr -d '\n')
          echo "irsa_role_arn=$S3_ROLE_ARN" >> $GITHUB_OUTPUT

      - name: Apply IRSA ServiceAccount
        run: |
          echo "üîß Applying IRSA SA"
          envsubst < data/irsa-sa.yaml.tpl > data/irsa-sa.yaml
          kubectl apply -f data/irsa-sa.yaml 

      - name: Generate restore-job.yaml
        env:
          DB_NAME: petclinic
          DB_USER: petuser
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          RDS_HOST: ${{ steps.rds.outputs.rds_host }}
        run: |
          echo "üõ†Ô∏è Generating restore-job.yaml"
          envsubst < data/restore-job.yaml.tpl > data/restore-job.yaml

      - name: Run Restore Job
        run: |
          echo "üì¶ Applying restore job"
          kubectl apply -f data/restore-job.yaml

      - name: Wait for Restore Job Completion
        run: |
          echo "‚è≥ Waiting for db-restore-job to complete..."
          kubectl wait --for=condition=complete --timeout=120s job/db-restore-job

      - name: Wait for RDS restore job to complete
        run: |
          kubectl wait --for=condition=complete job/db-restore-job --timeout=300s

      - name: Save RDS restore complete time
        run: echo "RDS_RESTORE_COMPLETE_TIME=$(date -u +"%Y-%m-%dT%H:%M:%SZ")" >> $GITHUB_ENV

      - name: Deploy Web & WAS YAMLs
        run: |
          kubectl apply -f web/
          kubectl apply -f was/

      - name: Wait for WAS pod to be ready
        run: |
          kubectl wait --for=condition=Ready pod -l app=was --timeout=300s
          echo "WAS_READY_TIME=$(date -u +"%Y-%m-%dT%H:%M:%SZ")" >> $GITHUB_ENV

      - name: Save Actions end time
        run: echo "ACTION_END_TIME=$(date -u +"%Y-%m-%dT%H:%M:%SZ")" >> $GITHUB_ENV

      - name: Install Google BigQuery SDK
        run: pip install --upgrade google-cloud-bigquery

      - name: Export to BigQuery
        env:
          BQ_KEY: ${{ secrets.BQ_KEY }}
          TRIGGER_ID: dr-${{ github.run_number }}
          SLACK_APPROVE_TIME: ${{ github.event.inputs.approve_time }}  # Cloud RunÏóêÏÑú Ï†ÑÎã¨
          START_TIME: ${{ env.START_TIME }}
          END_TIME: ${{ env.END_TIME }}

        run: python export_to_bigquery.py

      - name: Slack Notification (Success)
        if: success()
        run: |
          curl -X POST -H 'Content-type: application/json' \
            --data '{"text":"‚úÖ DR Ïù∏ÌîÑÎùº Î≥µÍµ¨Í∞Ä ÏÑ±Í≥µÏ†ÅÏúºÎ°ú ÏôÑÎ£åÎêòÏóàÏäµÎãàÎã§."}' \
            "${{ secrets.SLACK_WEBHOOK_URL }}"

      - name: Slack Notification (Failure)
        if: failure()
        run: |
          curl -X POST -H 'Content-type: application/json' \
            --data '{"text":"‚ùå DR Î≥µÍµ¨ Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§."}' \
            "${{ secrets.SLACK_WEBHOOK_URL }}"

